# Построение ETL-пайплайна. Автоматизация ежедневной обработки и загрузки данных.

## Входные данные:
В приложении есть два сервиса: лента новостей и мессенджер. Данные о действиях пользователей из каждого сервиса записываются в базу данных Clickhouse в отдельные таблицы:  **feed_actions** и **message_actions** соответственно. 

### Таблица feed_actions (лента новостей):
|user_id|post_id|action|time|gender|age|country|city|os|source|exp_group|
|-------|-------|------|----|------|---|-------|----|--|------|---------|
|номер пользователя|номер поста|просмотр/лайк|время действия|пол|возраст|страна|город|опер. сист.|источник трафика|номер группы|

### Таблица message_actions (мессенджер):
|user_id|receiver_id|time|gender|age|country|city|os|source|exp_group|
|-------|-------|----|------|---|-------|----|--|------|---------|
|номер отправителя|номер получателя|время действия|пол|возраст|страна|город|опер. сист.|источник трафика|номер группы|

## Задача: построить ETL-pipeline (создать DAG в Apache Airflow)
Ежедневно рассчитывать пользовательские метрики в разрезе по полу, возрасту и операционной системе (ос) и загружать их в новую таблицу.  

**Пользовательские метрики:**  
- количество просмотров
- количество лайков
- количество полученных сообщений
- количество отправленных сообщений
- количество получателей писем (скольким людям пишет пользователь)
- количество отправителей писем (сколько людей пишет пользователю)

Записать результат в финальную таблицу следующего формата:
|event_date|dimension|dimension_value|views|likes|messages_received|messages_sent|users_received|users_sent|
|----------|---------|---------------|-----|-----|-----------------|-------------|--------------|----------|
|Дата|Название среза|Значение среза|Количество просмотров|Количество лайков|Количество полученных сообщений|Количество отправленных сообщений|Количество получателей писем|Количество отправителей писем|

Каждый день таблица должна дополняться новыми данными. 

## Шаги выполнения:
1. В **feed_actions** для каждого пользователя посчитать число просмотров и лайков постов.
2. В **message_actions** для каждого пользователя посчитать, сколько он получает и отсылает сообщений, скольким людям он пишет, сколько людей пишут ему. **Каждая выгрузка формируется в отдельном таске DAG**.
3. Объединить две таблицы в одну.
4. В объединенной таблице посчитать все метрики в разрезе по полу, возрасту и ос. **Расчеты метрик для каждого среза формируются в отдельном таске DAG**.
5. Полученные данные с метриками записать в отдельную таблицу в **ClickHouse**.
6. Настроить расписание в DAG, чтобы скрипт срабатывал ежедневно в одно и то же время.

## Результат:
1. Создан **DAG в Apache Airflow**, в котором:
  - два таска для выгрузки данных из каждой таблицы (**extract_feed, extract_message**)
  - один таск для объединения таблиц (**union_data**)
  - три таска для расчета метрик по срезам (**transfrom_gender, transfrom_age, transfrom_os**)
  - один таск для загрузки метрик в финальную таблицу (**load**)
<image width="600" height="300" src="/DAG-ETL-Pipeline.png" alt="DAG">
2. DAG отрабатывает ежедневно T04:00:00, рассчитывая метрики за предыдущий день.
