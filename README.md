# Построение ETL-пайплайна в Apache Airflow. Автоматизация ежедневной обработки и загрузки данных.

## Входные данные:
В приложении есть два сервиса: лента новостей и мессенджер. Данные о действиях пользователей из каждого сервиса записываются в базу данных Clickhouse в отдельные таблицы:  **feed_actions** и **message_actions** соответственно. 

### Таблица feed_actions (лента новостей):
|user_id|post_id|action|time|gender|age|country|city|os|source|exp_group|
|-------|-------|------|----|------|---|-------|----|--|------|---------|
|номер пользователя|номер поста|просмотр/лайк|время действия|пол|возраст|страна|город|опер. сист.|источник трафика|номер группы|

### Таблица message_actions (мессенджер):
|user_id|receiver_id|time|gender|age|country|city|os|source|exp_group|
|-------|-------|----|------|---|-------|----|--|------|---------|
|номер отправителя|номер получателя|время действия|пол|возраст|страна|город|опер. сист.|источник трафика|номер группы|

## Задача: построить ETL-pipeline (создать DAG в Apache Airflow)
Ежедневно рассчитывать пользовательские метрики в разрезе по полу, возрасту и операционной системе (ос) и загружать их в новую таблицу.  

**Пользовательские метрики:**  
- количество просмотров
- количество лайков
- количество полученных сообщений
- количество отправленных сообщений
- количество получателей писем (скольким людям пишет пользователь)
- количество отправителей писем (сколько людей пишет пользователю)

Записать результат в финальную таблицу следующего формата:
|event_date|dimension|dimension_value|views|likes|messages_received|messages_sent|users_received|users_sent|
|----------|---------|---------------|-----|-----|-----------------|-------------|--------------|----------|
|Дата|Название среза|Значение среза|Количество просмотров|Количество лайков|Количество полученных сообщений|Количество отправленных сообщений|Количество получателей писем|Количество отправителей писем|

Каждый день таблица должна дополняться новыми данными. 

## Шаги выполнения:
### Извлечение данных (Extract):
- Настроить подключений к базам данных (Clickhouse)
- Настроить регулярное извлечение данных из указанных источников в соответствии с расписанием:
- В **feed_actions** для каждого пользователя посчитать число просмотров и лайков постов
- В **message_actions** для каждого пользователя посчитать, сколько он получает и отсылает сообщений, скольким людям он пишет, сколько людей пишут ему. **Каждая выгрузка формируется в отдельном таске DAG**
### Трансформация данных (Transform):
- Очистить и нормализовать данные, включая удаление дубликатов и заполнение пропущенных значений
- Примененить бизнес-логику для преобразования данных и подготовки их к загрузке
- Объединить две таблицы в одну.
- В объединенной таблице посчитать все метрики в разрезе по полу, возрасту и ос. **Расчеты метрик для каждого среза формируются в отдельном таске DAG**.
- Форматировать данные в соответствии с требованиями целевого хранилища.
### Загрузка данных (Load):
- Загрузить обработанные данные в целевое хранилище (Clickhouse). Полученные данные с метриками записать в отдельную таблицу в **ClickHouse**.
### Автоматизация с Apache Airflow:
- Настроить DAG (Directed Acyclic Graph) в Apache Airflow для автоматического запуска пайплайна по расписанию.

## Результат:
1. Создан **DAG в Apache Airflow**, в котором:
  - два таска для выгрузки данных из каждой таблицы (**extract_feed, extract_message**)
  - один таск для объединения таблиц (**union_data**)
  - три таска для расчета метрик по срезам (**transfrom_gender, transfrom_age, transfrom_os**)
  - один таск для загрузки метрик в финальную таблицу (**load**)
<image width="600" height="300" src="/DAG-ETL-Pipeline.png" alt="DAG">

2. Настроено расписание работы DAG для расчета метрик за предыдущий день.
3. Сокращено время на выполнение ETL-процессов и снижено число ошибок за счет автоматизации.
4. Повышена устойчивость и гибкость процесса обработки данных благодаря использованию Apache Airflow.
